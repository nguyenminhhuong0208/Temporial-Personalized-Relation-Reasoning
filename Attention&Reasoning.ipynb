{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WDzSLlRYLMNN",
        "outputId": "b578bbe8-5f86-488b-9fa7-89598e82a68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.68)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.7-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ca857af540d343de82e65dc88e731c29"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdSxpOgpJ5Bj",
        "outputId": "a6932153-a2c4-43a2-abaf-88f996d72a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mô hình LLM đã được khởi tạo thành công.\n",
            "Proceeding with reasoning using pre-loaded knowledge graph data...\n",
            "Running TRR for date range: 2025-03-31 to 2025-04-04\n",
            "Loaded 38 existing predictions from prediction_NER.csv\n",
            "\n",
            "--- Starting prediction for date: 2025-03-31T01:00:00+07:00 ---\n",
            "Prediction timestamp (UTC aware): 2025-03-30 18:00:00+00:00\n",
            "Attempting to load existing knowledge graph...\n",
            "Successfully loaded graph with 4648 nodes and 31000 edges from /content/knowledge_graph_p3_fixed_0227-0407.pkl\n",
            "Applying attention phase (PageRank-based filtering)...\n",
            "Using raw prediction date string: 2025-03-31T01:00:00+07:00\n",
            "Using prediction date (UTC aware): 2025-03-30 18:00:00+00:00\n",
            "Filtered out 6556 future edges from graph for TPPR calculation.\n",
            "Graph after future edge filtering: 4648 nodes, 24444 edges.\n",
            "Working with largest connected component: 3759 nodes, 24444 edges.\n",
            "Applying update_edge_decay_weights (node-to-node temporal decay)...\n",
            "Update Edge Decay Weights Summary (delta_days: decay_value): [(0.0, 1.0), (1.0, 0.36787944117144233), (2.0, 0.1353352832366127), (3.0, 0.049787068367863944), (4.0, 0.01831563888873418), (5.0, 0.006737946999085467), (6.0, 0.0024787521766663585), (7.0, 0.0009118819655545162), (8.0, 0.00033546262790251185), (9.0, 0.00012340980408667956), (10.0, 4.5399929762484854e-05), (11.0, 1.670170079024566e-05), (12.0, 6.14421235332821e-06), (13.0, 2.2603294069810542e-06), (14.0, 8.315287191035679e-07), (15.0, 3.059023205018258e-07), (16.0, 1.1253517471925912e-07), (17.0, 4.139937718785167e-08), (18.0, 1.522997974471263e-08), (19.0, 5.602796437537268e-09), (20.0, 2.061153622438558e-09), (21.0, 7.582560427911907e-10), (22.0, 2.7894680928689246e-10), (23.0, 1.026187963170189e-10), (24.0, 3.775134544279098e-11), (25.0, 1.3887943864964021e-11), (26.0, 5.109089028063325e-12), (27.0, 1.8795288165390832e-12), (28.0, 6.914400106940203e-13), (29.0, 2.543665647376923e-13), (30.0, 9.357622968840175e-14), (31.0, 3.442477108469977e-14)]\n",
            "Applying apply_tppr_decay_weights (edge-age decay, in days)...\n",
            "\n",
            "Computing TPPR scores on 3759 nodes and 24444 edges...\n",
            "\n",
            "--- Top 6 Nodes by TPPR Score (2025-03-30 18:00) ---\n",
            "- doanh nghiệp xây dựng quảng nam (Type: entity, Sector: N/A, Rel: N/A): 0.00853550\n",
            "- thị trường chứng khoán đông nam á (Type: entity, Sector: N/A, Rel: N/A): 0.00728112\n",
            "- giá cả hàng hóa việt nam (Type: entity, Sector: N/A, Rel: N/A): 0.00648671\n",
            "- người lao động đông nam á (Type: entity, Sector: N/A, Rel: N/A): 0.00637067\n",
            "- áp lực quản lý (Type: entity, Sector: N/A, Rel: N/A): 0.00586046\n",
            "- ngành công nghệ thông tin thế giới (Type: entity, Sector: N/A, Rel: N/A): 0.00573320\n",
            "\n",
            "Created subgraph (G_TRR) with 263 nodes and 3439 edges.\n",
            "Top 10 nodes by incoming edges (in G_TRR): [('giá cả hàng hóa việt nam', 115), ('người tiêu dùng việt nam', 98), ('ngân sách nhà nước việt nam', 84), ('lạm phát việt nam', 84), ('người lao động việt nam', 80), ('doanh nghiệp việt nam', 77), ('ngành công nghiệp việt nam', 75), ('ngành tài chính việt nam', 69), ('doanh nghiệp xuất khẩu việt nam', 68), ('áp lực quản lý', 67)]\n",
            "Running final reasoning...\n",
            "\n",
            "Tuple đầu vào cho suy luận:\n",
            "Số cạnh: 3439\n",
            "\n",
            "Final Prediction:\n",
            "Explanation: Danh mục cổ phiếu dự kiến sẽ sập giá vào ngày 2025-03-31T01:00:00+07:00 do sự tích lũy của các yếu tố tiêu cực vĩ mô và các vấn đề cụ thể trong các ngành trọng điểm, bất chấp một số nỗ lực hỗ trợ từ chính phủ.\n",
            "\n",
            "Các lý do chính bao gồm:\n",
            "\n",
            "1.  **Lạm phát gia tăng và áp lực chi phí:** Đồ thị tri thức cho thấy \"Lạm phát Việt Nam\" liên tục \"POSITIVE TO\" nhiều doanh nghiệp và ngành (ví dụ: doanh nghiệp xây dựng, doanh nghiệp chế biến thực phẩm, ngành bất động sản, ngành công nghiệp, ngành dầu khí, ngành bán lẻ) trong suốt tháng 3, đặc biệt là vào các ngày 02, 06, 11, 15, 17, 19, 20, 23, 25, 26, 28, 29. Điều này cho thấy chi phí đầu vào tăng cao và áp lực lên lợi nhuận của các doanh nghiệp trong danh mục (HPG, VHM, VCG, GAS, MSN, MWG). Mặc dù lạm phát có thể \"NEGATIVE TO\" một số ngành (ví dụ: ngành tài chính, người tiêu dùng), nhưng tác động tích cực của nó lên chi phí sản xuất và kinh doanh là rõ ràng, gây áp lực giảm giá cổ phiếu.\n",
            "\n",
            "2.  **Nợ công gia tăng:** \"Nợ công Việt Nam\" liên tục \"POSITIVE TO\" nhiều thực thể quan trọng như \"doanh nghiệp việt nam\", \"ngành tài chính việt nam\", \"ngân sách nhà nước việt nam\", \"ngân hàng nhà nước việt nam\", \"người dân việt nam\", \"thị trường chứng khoán việt nam\" trong suốt tháng 3 (ví dụ: 04, 06, 08, 14, 15, 17, 20, 23, 29). Điều này cho thấy gánh nặng tài chính ngày càng tăng của chính phủ, có thể dẫn đến việc cắt giảm chi tiêu công hoặc tăng thuế trong tương lai, ảnh hưởng tiêu cực đến tăng trưởng kinh tế và lợi nhuận doanh nghiệp.\n",
            "\n",
            "3.  **Rủi ro thị trường tăng cao:** \"Rủi ro thị trường\" thường xuyên \"POSITIVE TO\" các doanh nghiệp, thị trường bất động sản, thị trường chứng khoán, nhà đầu tư và người tiêu dùng (ví dụ: 03, 04, 07, 08, 09, 11, 14, 15, 16, 18, 22, 24, 26, 27, 28, 29). Điều này cho thấy sự bất ổn và lo ngại ngày càng tăng trong môi trường kinh doanh và đầu tư, khiến nhà đầu tư có xu hướng rút vốn hoặc giảm đầu tư, gây áp lực giảm giá lên toàn bộ thị trường.\n",
            "\n",
            "4.  **Vấn đề cụ thể của các ngành trong danh mục:**\n",
            "    *   **Công nghệ (FPT):** \"Article_252: FPT mất gần 1 tỷ USD vốn hóa từ đầu năm do áp lực từ AI giá rẻ\" vào ngày 2025-03-12 là một tin tức tiêu cực trực tiếp và mạnh mẽ đối với FPT và ngành công nghệ thông tin Việt Nam. Mặc dù có các yếu tố tích cực từ công nghệ toàn cầu, nhưng áp lực cạnh tranh và mất vốn hóa đã được ghi nhận.\n",
            "    *   **Bất động sản & Xây dựng (VHM, VCG):** Mặc dù nhận được sự hỗ trợ từ chính phủ và Bộ Xây dựng, ngành này cũng đối mặt với nhiều thách thức. Đặc biệt, sự kiện \"Article_536: Quảng Nam thanh tra dự án hồ chứa nước gần 300 tỷ\" vào ngày 2025-03-26 là một tin tức tiêu cực trực tiếp đối với các doanh nghiệp xây dựng và bất động sản, cho thấy rủi ro về pháp lý và dự án. Ngoài ra, \"doanh nghiệp xây dựng việt nam\" và \"giá nguyên vật liệu xây dựng việt nam\" có các mối quan hệ \"NEGATIVE TO\" chính chúng và các yếu tố quản lý vào ngày 2025-03-22, cho thấy những khó khăn nội tại.\n",
            "    *   **Năng lượng (GAS):** Ngành dầu khí liên tục chịu áp lực tiêu cực từ nhiều phía, bao gồm cả \"doanh nghiệp dầu khí việt nam\" bị \"NEGATIVE TO\" chính phủ, nền kinh tế, và các yếu tố khác (ví dụ: 03, 04, 06, 07, 11, 20, 24, 29, 30). Điều này cho thấy triển vọng kém khả quan cho cổ phiếu GAS.\n",
            "    *   **Bán lẻ (MSN, MWG):** Ngành bán lẻ chịu tác động mạnh từ lạm phát và hành vi tiêu dùng. Nhiều mối quan hệ \"NEGATIVE TO\" doanh nghiệp bán lẻ từ người tiêu dùng, lạm phát, và các ngành khác (ví dụ: 01, 02, 03, 04, 14, 20, 25, 26, 29, 30) cho thấy một môi trường kinh doanh đầy thách thức.\n",
            "    *   **Tài chính (SSI, VCB):** Mặc dù có sự hỗ trợ từ chính phủ, ngành tài chính và ngân hàng cũng đối mặt với nhiều áp lực tiêu cực từ lạm phát, rủi ro thị trường và các mối quan hệ \"NEGATIVE TO\" khác (ví dụ: 01, 02, 06, 07, 09, 10, 12, 13, 14, 17, 18, 22, 23, 24, 29).\n",
            "\n",
            "Tổng hợp lại, mặc dù có những yếu tố tích cực và sự can thiệp của chính phủ nhằm ổn định thị trường, nhưng sự kết hợp của lạm phát tăng cao, nợ công gia tăng, rủi ro thị trường leo thang và các vấn đề cụ thể trong các ngành trọng điểm (công nghệ, bất động sản, năng lượng, bán lẻ) tạo ra một bức tranh kinh tế đầy thách thức. Những áp lực này đủ mạnh để gây ra một đợt sụt giảm giá đáng kể (lên tới 5%) cho danh mục cổ phiếu vào ngày 2025-03-31.\n",
            "\n",
            "Crash: Yes\n",
            "Prediction for 2025-03-31: Yes\n",
            "Waiting 60 seconds before next prediction...\n",
            "\n",
            "--- Starting prediction for date: 2025-04-01T01:00:00+07:00 ---\n",
            "Prediction timestamp (UTC aware): 2025-03-31 18:00:00+00:00\n",
            "Attempting to load existing knowledge graph...\n",
            "Successfully loaded graph with 4648 nodes and 31000 edges from /content/knowledge_graph_p3_fixed_0227-0407.pkl\n",
            "Applying attention phase (PageRank-based filtering)...\n",
            "Using raw prediction date string: 2025-04-01T01:00:00+07:00\n",
            "Using prediction date (UTC aware): 2025-03-31 18:00:00+00:00\n",
            "Filtered out 5384 future edges from graph for TPPR calculation.\n",
            "Graph after future edge filtering: 4648 nodes, 25616 edges.\n",
            "Working with largest connected component: 3909 nodes, 25616 edges.\n",
            "Applying update_edge_decay_weights (node-to-node temporal decay)...\n",
            "Update Edge Decay Weights Summary (delta_days: decay_value): [(0.0, 1.0), (1.0, 0.36787944117144233), (2.0, 0.1353352832366127), (3.0, 0.049787068367863944), (4.0, 0.01831563888873418), (5.0, 0.006737946999085467), (6.0, 0.0024787521766663585), (7.0, 0.0009118819655545162), (8.0, 0.00033546262790251185), (9.0, 0.00012340980408667956), (10.0, 4.5399929762484854e-05), (11.0, 1.670170079024566e-05), (12.0, 6.14421235332821e-06), (13.0, 2.2603294069810542e-06), (14.0, 8.315287191035679e-07), (15.0, 3.059023205018258e-07), (16.0, 1.1253517471925912e-07), (17.0, 4.139937718785167e-08), (18.0, 1.522997974471263e-08), (19.0, 5.602796437537268e-09), (20.0, 2.061153622438558e-09), (21.0, 7.582560427911907e-10), (22.0, 2.7894680928689246e-10), (23.0, 1.026187963170189e-10), (24.0, 3.775134544279098e-11), (25.0, 1.3887943864964021e-11), (26.0, 5.109089028063325e-12), (27.0, 1.8795288165390832e-12), (28.0, 6.914400106940203e-13), (29.0, 2.543665647376923e-13), (30.0, 9.357622968840175e-14), (31.0, 3.442477108469977e-14), (32.0, 1.2664165549094176e-14)]\n",
            "Applying apply_tppr_decay_weights (edge-age decay, in days)...\n",
            "\n",
            "Computing TPPR scores on 3909 nodes and 25616 edges...\n",
            "\n",
            "--- Top 6 Nodes by TPPR Score (2025-03-31 18:00) ---\n",
            "- thị trường chứng khoán đông nam á (Type: entity, Sector: N/A, Rel: N/A): 0.00731214\n",
            "- doanh nghiệp công nghệ thông tin trung quốc (Type: entity, Sector: N/A, Rel: N/A): 0.00692891\n",
            "- giá cả hàng hóa việt nam (Type: entity, Sector: N/A, Rel: N/A): 0.00680833\n",
            "- người lao động đông nam á (Type: entity, Sector: N/A, Rel: N/A): 0.00639470\n",
            "- doanh nghiệp xây dựng quảng nam (Type: entity, Sector: N/A, Rel: N/A): 0.00638865\n",
            "- thị trường bán lẻ việt nam (Type: entity, Sector: N/A, Rel: N/A): 0.00544023\n",
            "\n",
            "Created subgraph (G_TRR) with 227 nodes and 3062 edges.\n",
            "Top 10 nodes by incoming edges (in G_TRR): [('giá cả hàng hóa việt nam', 121), ('người tiêu dùng việt nam', 102), ('người lao động việt nam', 84), ('ngành công nghiệp việt nam', 72), ('lạm phát việt nam', 72), ('doanh nghiệp xuất khẩu việt nam', 71), ('doanh nghiệp việt nam', 68), ('ngân sách nhà nước việt nam', 67), ('doanh nghiệp bán lẻ việt nam', 65), ('ngành tài chính việt nam', 58)]\n",
            "Running final reasoning...\n",
            "\n",
            "Tuple đầu vào cho suy luận:\n",
            "Số cạnh: 3062\n",
            "\n",
            "Final Prediction:\n",
            "Explanation:\n",
            "Dựa trên đồ thị tri thức được cung cấp, có nhiều yếu tố cho thấy khả năng danh mục cổ phiếu này sẽ sập giá vào ngày 2025-04-01T01:00:00+07:00:\n",
            "\n",
            "1.  **Tín hiệu tiêu cực trực tiếp từ thị trường chứng khoán:** Sự kiện quan trọng nhất là vào ngày **2025-03-22**, có thông tin \"Article_444: VN-Index điều chỉnh sau 8 tuần tăng, dòng vốn ngoại bán ròng, tâm lý thận trọng\" có tác động **NEGATIVE TO** \"thị trường chứng khoán việt nam\". Đây là một tín hiệu cực kỳ mạnh mẽ và trực tiếp cho thấy thị trường đang trong giai đoạn điều chỉnh giảm sâu, với việc nhà đầu tư nước ngoài bán ròng và tâm lý thận trọng lan rộng. Một đợt điều chỉnh sau 8 tuần tăng thường có thể dẫn đến mức giảm đáng kể, phù hợp với định nghĩa \"sập giá\" (giảm tới 5%).\n",
            "\n",
            "2.  **Áp lực lạm phát và tác động tiêu cực đến kinh tế vĩ mô:**\n",
            "    *   \"Lạm phát Việt Nam\" liên tục có các tác động **NEGATIVE TO** \"doanh nghiệp việt nam\", \"ngân hàng việt nam\", \"người tiêu dùng việt nam\" (2025-03-01), và \"đời sống người dân việt nam\" (2025-03-31). Mặc dù có một số mối quan hệ \"POSITIVE TO\" lạm phát (ví dụ: doanh nghiệp xây dựng, ngành công nghệ thông tin), nhưng nhìn chung, lạm phát cao sẽ làm giảm sức mua, ảnh hưởng đến lợi nhuận doanh nghiệp và tâm lý nhà đầu tư.\n",
            "    *   \"Nền kinh tế Việt Nam\" cũng chịu nhiều tác động **NEGATIVE TO** từ các yếu tố như \"ngành tài chính việt nam\", \"ngân hàng việt nam\", \"người lao động việt nam\", \"người tiêu dùng việt nam\" (2025-03-06), và \"người dân việt nam\", \"người mua nhà việt nam\" (2025-03-24). Một nền kinh tế suy yếu sẽ kéo theo sự sụt giảm của thị trường chứng khoán.\n",
            "\n",
            "3.  **Tác động tiêu cực đến các ngành và doanh nghiệp chủ chốt trong danh mục:**\n",
            "    *   **Ngành tài chính và ngân hàng (SSI, VCB):** \"Ngành tài chính việt nam\" và \"ngân hàng việt nam\" chịu nhiều tác động **NEGATIVE TO** \"thị trường chứng khoán việt nam\" (2025-02-27). Đặc biệt, \"ngân hàng nhà nước việt nam\" có nhiều tác động **NEGATIVE TO** \"ngành tài chính việt nam\" và \"ngân hàng việt nam\" (2025-03-01), cho thấy các chính sách tiền tệ có thể đang thắt chặt hoặc có vấn đề.\n",
            "    *   **Ngành xây dựng và bất động sản (VHM, VCG):** Mặc dù có nhiều tác động tích cực, nhưng cũng có các tác động **NEGATIVE TO** đáng kể như \"ngành xây dựng việt nam\" **NEGATIVE TO** \"doanh nghiệp xây dựng việt nam\" (2025-02-27), \"thị trường bất động sản việt nam\" **NEGATIVE TO** \"ngành xây dựng việt nam\" (2025-03-01). Đặc biệt, thông tin thanh tra dự án ở Quảng Nam (2025-03-26) có tác động **NEGATIVE TO** \"doanh nghiệp xây dựng quảng nam\", có thể lan rộng tâm lý tiêu cực ra toàn ngành.\n",
            "    *   **Ngành dầu khí (GAS):** \"Doanh nghiệp dầu khí việt nam\" và \"ngành công nghiệp dầu khí việt nam\" chịu nhiều tác động **NEGATIVE TO** từ \"giá nhiên liệu thế giới\" (2025-03-03) và các yếu tố khác.\n",
            "    *   **Ngành bán lẻ (MSN, MWG):** \"Doanh nghiệp bán lẻ việt nam\" và \"ngành bán lẻ việt nam\" chịu nhiều tác động **NEGATIVE TO** từ \"người tiêu dùng việt nam\" (2025-03-01), \"thị trường chứng khoán việt nam\" (2025-03-01), và các yếu tố nội ngành.\n",
            "\n",
            "4.  **Dòng vốn ngoại bán ròng:** Thông tin từ Article_444 (2025-03-22) về \"dòng vốn ngoại bán ròng\" là một chỉ báo rất quan trọng về tâm lý nhà đầu tư nước ngoài đối với thị trường Việt Nam, thường dẫn đến áp lực giảm giá mạnh.\n",
            "\n",
            "Mặc dù có một số tác động tích cực rải rác đến các ngành và doanh nghiệp, nhưng các yếu tố tiêu cực tổng thể, đặc biệt là sự điều chỉnh của VN-Index, dòng vốn ngoại bán ròng, và áp lực lạm phát, cho thấy một kịch bản sập giá là rất có khả năng xảy ra.\n",
            "\n",
            "Crash: Yes\n",
            "Prediction for 2025-04-01: Yes\n",
            "Waiting 60 seconds before next prediction...\n",
            "\n",
            "--- Starting prediction for date: 2025-04-02T01:00:00+07:00 ---\n",
            "Prediction timestamp (UTC aware): 2025-04-01 18:00:00+00:00\n",
            "Attempting to load existing knowledge graph...\n",
            "Successfully loaded graph with 4648 nodes and 31000 edges from /content/knowledge_graph_p3_fixed_0227-0407.pkl\n",
            "Applying attention phase (PageRank-based filtering)...\n",
            "Using raw prediction date string: 2025-04-02T01:00:00+07:00\n",
            "Using prediction date (UTC aware): 2025-04-01 18:00:00+00:00\n",
            "Filtered out 4741 future edges from graph for TPPR calculation.\n",
            "Graph after future edge filtering: 4648 nodes, 26259 edges.\n",
            "Working with largest connected component: 4002 nodes, 26259 edges.\n",
            "Applying update_edge_decay_weights (node-to-node temporal decay)...\n",
            "Update Edge Decay Weights Summary (delta_days: decay_value): [(0.0, 1.0), (1.0, 0.36787944117144233), (2.0, 0.1353352832366127), (3.0, 0.049787068367863944), (4.0, 0.01831563888873418), (5.0, 0.006737946999085467), (6.0, 0.0024787521766663585), (7.0, 0.0009118819655545162), (8.0, 0.00033546262790251185), (9.0, 0.00012340980408667956), (10.0, 4.5399929762484854e-05), (11.0, 1.670170079024566e-05), (12.0, 6.14421235332821e-06), (13.0, 2.2603294069810542e-06), (14.0, 8.315287191035679e-07), (15.0, 3.059023205018258e-07), (16.0, 1.1253517471925912e-07), (17.0, 4.139937718785167e-08), (18.0, 1.522997974471263e-08), (19.0, 5.602796437537268e-09), (20.0, 2.061153622438558e-09), (21.0, 7.582560427911907e-10), (22.0, 2.7894680928689246e-10), (23.0, 1.026187963170189e-10), (24.0, 3.775134544279098e-11), (25.0, 1.3887943864964021e-11), (26.0, 5.109089028063325e-12), (27.0, 1.8795288165390832e-12), (28.0, 6.914400106940203e-13), (29.0, 2.543665647376923e-13), (30.0, 9.357622968840175e-14), (31.0, 3.442477108469977e-14), (32.0, 1.2664165549094176e-14), (33.0, 4.658886145103398e-15)]\n",
            "Applying apply_tppr_decay_weights (edge-age decay, in days)...\n",
            "\n",
            "Computing TPPR scores on 4002 nodes and 26259 edges...\n",
            "\n",
            "--- Top 6 Nodes by TPPR Score (2025-04-01 18:00) ---\n",
            "- thị trường chứng khoán đông nam á (Type: entity, Sector: N/A, Rel: N/A): 0.00684526\n",
            "- ngân hàng nhà nước việt nam (Type: entity, Sector: N/A, Rel: N/A): 0.00630814\n",
            "- người lao động đông nam á (Type: entity, Sector: N/A, Rel: N/A): 0.00598357\n",
            "- doanh nghiệp xây dựng quảng nam (Type: entity, Sector: N/A, Rel: N/A): 0.00575947\n",
            "- giá cả hàng hóa việt nam (Type: entity, Sector: N/A, Rel: N/A): 0.00568621\n",
            "- doanh nghiệp công nghệ thông tin trung quốc (Type: entity, Sector: N/A, Rel: N/A): 0.00502118\n",
            "\n",
            "Created subgraph (G_TRR) with 308 nodes and 4283 edges.\n",
            "Top 10 nodes by incoming edges (in G_TRR): [('người tiêu dùng việt nam', 127), ('giá cả hàng hóa việt nam', 122), ('lạm phát việt nam', 109), ('ngân hàng nhà nước việt nam', 108), ('ngành tài chính việt nam', 106), ('doanh nghiệp việt nam', 106), ('ngân hàng việt nam', 102), ('người lao động việt nam', 99), ('thị trường chứng khoán việt nam', 91), ('ngân sách nhà nước việt nam', 90)]\n",
            "Running final reasoning...\n",
            "\n",
            "Tuple đầu vào cho suy luận:\n",
            "Số cạnh: 4283\n",
            "\n",
            "Final Prediction:\n",
            "Explanation:\n",
            "Dựa trên đồ thị tri thức được cung cấp, có nhiều yếu tố tiêu cực mạnh mẽ diễn ra vào ngày 2025-04-01, ngay trước thời điểm dự đoán, có khả năng gây ra sự sập giá đáng kể cho danh mục cổ phiếu.\n",
            "\n",
            "Các yếu tố tiêu cực chính:\n",
            "1.  **Thị trường chứng khoán Việt Nam tự suy yếu:** Quan hệ `(2025-04-01, thị trường chứng khoán việt nam, NEGATIVE TO, thị trường chứng khoán việt nam)` cho thấy một vòng lặp tiêu cực tự thân của thị trường, trực tiếp ảnh hưởng đến SSI và tâm lý chung của toàn bộ danh mục.\n",
            "2.  **Doanh nghiệp lớn và ngành công nghiệp bị ảnh hưởng tiêu cực:**\n",
            "    *   `(2025-04-01, doanh nghiệp lớn việt nam, NEGATIVE TO, thị trường chứng khoán việt nam)`: Điều này tác động trực tiếp đến các cổ phiếu vốn hóa lớn trong danh mục như FPT, SSI, VCB, VHM, HPG, GAS, MSN, MWG, GVR, VCG.\n",
            "    *   `(2025-04-01, ngành công nghiệp việt nam, NEGATIVE TO, doanh nghiệp lớn việt nam)`: Gây áp lực lên các cổ phiếu công nghiệp và sản xuất như HPG, GAS, GVR, FPT, VCG.\n",
            "    *   `(2025-04-01, ngành công nghiệp dầu khí việt nam, NEGATIVE TO, ngành công nghiệp dầu khí việt nam)`: Ảnh hưởng trực tiếp đến GAS.\n",
            "3.  **Tâm lý nhà đầu tư và doanh nghiệp suy giảm:**\n",
            "    *   `(2025-04-01, nhà đầu tư tiền ảo, NEGATIVE TO, doanh nghiệp việt nam)`: Tác động tiêu cực đến tất cả các doanh nghiệp trong danh mục.\n",
            "    *   `(2025-04-01, nhà đầu tư tiền ảo, NEGATIVE TO, nhà đầu tư chứng khoán việt nam)`: Gây áp lực trực tiếp lên SSI và tâm lý nhà đầu tư nói chung.\n",
            "    *   `(2025-04-01, doanh nghiệp bán lẻ việt nam, NEGATIVE TO, ngành bán lẻ việt nam)`: Ảnh hưởng trực tiếp đến MSN và MWG.\n",
            "    *   `(2025-04-01, người mua nhà việt nam, NEGATIVE TO, nhà đầu tư chứng khoán việt nam)`: Gây áp lực lên nhà đầu tư chứng khoán.\n",
            "4.  **Ngân hàng và rủi ro tín dụng:** `(2025-04-01, ngân hàng lâm đồng, POSITIVE TO, rủi ro tín dụng)` cho thấy rủi ro tín dụng gia tăng, mặc dù là một ngân hàng cụ thể, nhưng có thể phản ánh xu hướng chung hoặc tâm lý lo ngại về ngành ngân hàng, ảnh hưởng đến VCB.\n",
            "5.  **Thị trường chứng khoán thế giới tiêu cực:** `(2025-04-01, thị trường chứng khoán thế giới, NEGATIVE TO, doanh nghiệp công nghệ thông tin việt nam)` tác động trực tiếp đến FPT và có thể lan tỏa sang các cổ phiếu khác.\n",
            "\n",
            "Mặc dù có một số yếu tố tích cực nhỏ như `(2025-04-01, ngân sách nhà nước Việt Nam, POSITIVE TO, ngành bất động sản việt nam)` (tích cực cho VHM) hoặc `(2025-04-01, áp lực quản lý, POSITIVE TO, ngân hàng việt nam)` (tích cực cho VCB), nhưng chúng không đủ mạnh để đối trọng với sự lan rộng và mức độ nghiêm trọng của các yếu tố tiêu cực đã nêu, đặc biệt là các yếu tố ảnh hưởng đến toàn bộ thị trường và các doanh nghiệp lớn. Sự tự suy yếu của thị trường chứng khoán Việt Nam và tác động tiêu cực từ nhà đầu tư tiền ảo đến toàn bộ doanh nghiệp Việt Nam là những tín hiệu rất đáng lo ngại.\n",
            "\n",
            "Crash: Yes\n",
            "Prediction for 2025-04-02: Yes\n",
            "Waiting 60 seconds before next prediction...\n",
            "\n",
            "--- Starting prediction for date: 2025-04-03T01:00:00+07:00 ---\n",
            "Prediction timestamp (UTC aware): 2025-04-02 18:00:00+00:00\n",
            "Attempting to load existing knowledge graph...\n",
            "Successfully loaded graph with 4648 nodes and 31000 edges from /content/knowledge_graph_p3_fixed_0227-0407.pkl\n",
            "Applying attention phase (PageRank-based filtering)...\n",
            "Using raw prediction date string: 2025-04-03T01:00:00+07:00\n",
            "Using prediction date (UTC aware): 2025-04-02 18:00:00+00:00\n",
            "Filtered out 3515 future edges from graph for TPPR calculation.\n",
            "Graph after future edge filtering: 4648 nodes, 27485 edges.\n",
            "Working with largest connected component: 4173 nodes, 27451 edges.\n",
            "Applying update_edge_decay_weights (node-to-node temporal decay)...\n",
            "Update Edge Decay Weights Summary (delta_days: decay_value): [(0.0, 1.0), (1.0, 0.36787944117144233), (2.0, 0.1353352832366127), (3.0, 0.049787068367863944), (4.0, 0.01831563888873418), (5.0, 0.006737946999085467), (6.0, 0.0024787521766663585), (7.0, 0.0009118819655545162), (8.0, 0.00033546262790251185), (9.0, 0.00012340980408667956), (10.0, 4.5399929762484854e-05), (11.0, 1.670170079024566e-05), (12.0, 6.14421235332821e-06), (13.0, 2.2603294069810542e-06), (14.0, 8.315287191035679e-07), (15.0, 3.059023205018258e-07), (16.0, 1.1253517471925912e-07), (17.0, 4.139937718785167e-08), (18.0, 1.522997974471263e-08), (19.0, 5.602796437537268e-09), (20.0, 2.061153622438558e-09), (21.0, 7.582560427911907e-10), (22.0, 2.7894680928689246e-10), (23.0, 1.026187963170189e-10), (24.0, 3.775134544279098e-11), (25.0, 1.3887943864964021e-11), (26.0, 5.109089028063325e-12), (27.0, 1.8795288165390832e-12), (28.0, 6.914400106940203e-13), (29.0, 2.543665647376923e-13), (30.0, 9.357622968840175e-14), (31.0, 3.442477108469977e-14), (32.0, 1.2664165549094176e-14), (33.0, 4.658886145103398e-15), (34.0, 1.713908431542013e-15)]\n",
            "Applying apply_tppr_decay_weights (edge-age decay, in days)...\n",
            "\n",
            "Computing TPPR scores on 4173 nodes and 27451 edges...\n",
            "\n",
            "--- Top 6 Nodes by TPPR Score (2025-04-02 18:00) ---\n",
            "- thị trường bán lẻ việt nam (Type: entity, Sector: N/A, Rel: N/A): 0.01735712\n",
            "- thị trường chứng khoán đông nam á (Type: entity, Sector: N/A, Rel: N/A): 0.00676392\n",
            "- doanh nghiệp công nghệ thông tin trung quốc (Type: entity, Sector: N/A, Rel: N/A): 0.00595944\n",
            "- người lao động đông nam á (Type: entity, Sector: N/A, Rel: N/A): 0.00590826\n",
            "- người vay việt nam (Type: entity, Sector: N/A, Rel: N/A): 0.00512140\n",
            "- doanh nghiệp công nghiệp trung quốc (Type: entity, Sector: N/A, Rel: N/A): 0.00454005\n",
            "\n",
            "Created subgraph (G_TRR) with 219 nodes and 3165 edges.\n",
            "Top 10 nodes by incoming edges (in G_TRR): [('người vay việt nam', 111), ('ngân hàng việt nam', 111), ('doanh nghiệp việt nam', 97), ('ngành tài chính việt nam', 92), ('thị trường chứng khoán việt nam', 91), ('người gửi tiền việt nam', 78), ('lạm phát việt nam', 78), ('người tiêu dùng việt nam', 69), ('người lao động việt nam', 65), ('ngân sách nhà nước việt nam', 63)]\n",
            "Running final reasoning...\n",
            "\n",
            "Tuple đầu vào cho suy luận:\n",
            "Số cạnh: 3165\n",
            "\n",
            "Final Prediction:\n",
            "Dự đoán cho ngày 2025-04-03T01:00:00+07:00:\n",
            "\n",
            "Explanation:\n",
            "Dựa trên đồ thị tri thức được cung cấp, có nhiều yếu tố tiêu cực mạnh mẽ tác động đến danh mục cổ phiếu vào thời điểm gần ngày 2025-04-03, đặc biệt là từ ngày 2025-03-30 đến 2025-04-02.\n",
            "\n",
            "1.  **Tình hình nợ xấu và rủi ro tín dụng gia tăng:**\n",
            "    *   Vào ngày 2025-03-30, `nợ xấu` được ghi nhận là `POSITIVE TO` (tức là tác động tiêu cực đến) `doanh nghiệp việt nam`, `ngân hàng việt nam`, `người vay việt nam`, và `thị trường chứng khoán việt nam`. Điều này ảnh hưởng trực tiếp và tiêu cực đến hầu hết các cổ phiếu trong danh mục như VCB (ngân hàng), VHM, VCG (bất động sản/xây dựng), HPG, GAS, GVR (doanh nghiệp nói chung), SSI (chứng khoán), và MSN, MWG (bán lẻ).\n",
            "    *   Cùng ngày 2025-03-30, `áp lực tài chính` cũng `POSITIVE TO` `ngân hàng việt nam`, `người mua nhà việt nam`, `người vay việt nam`, và `rủi ro tín dụng`, cho thấy tình hình tài chính chung đang xấu đi, đặc biệt là đối với ngành ngân hàng và bất động sản.\n",
            "    *   Đến ngày 2025-04-02, `rủi ro tín dụng` tiếp tục `POSITIVE TO` `cổ phiếu ngân hàng việt nam`, `doanh nghiệp xây dựng việt nam`, `ngân hàng việt nam`, `người vay việt nam`, và `thị trường bất động sản việt nam`. Điều này cho thấy rủi ro trong hệ thống tài chính và bất động sản đang tăng cao, đe dọa trực tiếp đến VCB, SSI, VHM, VCG.\n",
            "\n",
            "2.  **Tác động tiêu cực từ ngành ngân hàng và thị trường chứng khoán:**\n",
            "    *   Vào ngày 2025-04-02, `Ngân hàng Việt Nam` được ghi nhận `NEGATIVE TO` `doanh nghiệp bất động sản việt nam`. Điều này cho thấy sự khó khăn trong việc cấp vốn cho ngành bất động sản (VHM) từ phía ngân hàng (VCB).\n",
            "    *   Cũng trong ngày 2025-04-02, `ngân hàng việt nam; Việt Nam; Tài chính` có mối quan hệ `NEGATIVE TO` `cổ phiếu ngân hàng việt nam`, `doanh nghiệp xây dựng việt nam`, `người mua nhà việt nam`, `người vay việt nam`, và `thị trường bất động sản việt nam`. Đây là một tín hiệu cực kỳ tiêu cực, cho thấy chính ngành ngân hàng đang gặp vấn đề và tác động xấu đến các ngành liên quan mật thiết như bất động sản (VHM), xây dựng (VCG), và chính cổ phiếu ngân hàng (VCB) cũng như thị trường chứng khoán (SSI).\n",
            "    *   `cổ phiếu ngân hàng việt nam; Việt Nam; Tài chính` cũng `NEGATIVE TO` `ngân hàng việt nam`, `người gửi tiền việt nam`, `người vay việt nam`, `nhà đầu tư chứng khoán việt nam`, và `thị trường chứng khoán việt nam` vào ngày 2025-04-02. Điều này cho thấy cổ phiếu ngân hàng (VCB) đang chịu áp lực giảm giá mạnh và kéo theo cả thị trường chứng khoán (SSI).\n",
            "    *   Vào ngày 2025-04-01, `thị trường chứng khoán việt nam` tự `NEGATIVE TO` chính nó, cho thấy xu hướng giảm giá hoặc bất ổn.\n",
            "\n",
            "3.  **Các yếu tố tiêu cực khác:**\n",
            "    *   `Lạm phát việt nam` `POSITIVE TO` `nợ công việt nam` vào ngày 2025-04-02, cho thấy gánh nặng nợ công có thể tăng lên do lạm phát, ảnh hưởng đến ổn định kinh tế vĩ mô.\n",
            "    *   `doanh nghiệp bán dẫn trung quốc` `NEGATIVE TO` `doanh nghiệp công nghệ thông tin việt nam` (FPT) vào ngày 2025-04-02, cho thấy áp lực cạnh tranh hoặc khó khăn từ thị trường quốc tế đối với FPT.\n",
            "    *   `doanh nghiệp tmđt việt nam` `NEGATIVE TO` `doanh nghiệp bán lẻ việt nam` (MSN, MWG) vào ngày 2025-04-02, cho thấy sự cạnh tranh hoặc khó khăn trong ngành bán lẻ.\n",
            "\n",
            "Mặc dù có một số yếu tố tích cực như việc giảm lãi suất huy động và các gói tín dụng hỗ trợ, nhưng những tác động tiêu cực từ nợ xấu, rủi ro tín dụng, và sự suy yếu của ngành ngân hàng và bất động sản là rất mạnh và trực tiếp, có khả năng gây ra một đợt giảm giá mạnh trên diện rộng. Đặc biệt, các mối quan hệ `NEGATIVE TO` từ các thực thể cốt lõi như `Ngân hàng Việt Nam` và `cổ phiếu ngân hàng việt nam` đến nhiều thành phần quan trọng của nền kinh tế và thị trường chứng khoán là dấu hiệu đáng báo động.\n",
            "\n",
            "Crash: Yes\n",
            "Prediction for 2025-04-03: Yes\n",
            "Waiting 60 seconds before next prediction...\n",
            "\n",
            "--- Starting prediction for date: 2025-04-04T01:00:00+07:00 ---\n",
            "Prediction timestamp (UTC aware): 2025-04-03 18:00:00+00:00\n",
            "Attempting to load existing knowledge graph...\n",
            "Successfully loaded graph with 4648 nodes and 31000 edges from /content/knowledge_graph_p3_fixed_0227-0407.pkl\n",
            "Applying attention phase (PageRank-based filtering)...\n",
            "Using raw prediction date string: 2025-04-04T01:00:00+07:00\n",
            "Using prediction date (UTC aware): 2025-04-03 18:00:00+00:00\n",
            "Filtered out 2803 future edges from graph for TPPR calculation.\n",
            "Graph after future edge filtering: 4648 nodes, 28197 edges.\n",
            "Working with largest connected component: 4251 nodes, 28163 edges.\n",
            "Applying update_edge_decay_weights (node-to-node temporal decay)...\n",
            "Update Edge Decay Weights Summary (delta_days: decay_value): [(0.0, 1.0), (1.0, 0.36787944117144233), (2.0, 0.1353352832366127), (3.0, 0.049787068367863944), (4.0, 0.01831563888873418), (5.0, 0.006737946999085467), (6.0, 0.0024787521766663585), (7.0, 0.0009118819655545162), (8.0, 0.00033546262790251185), (9.0, 0.00012340980408667956), (10.0, 4.5399929762484854e-05), (11.0, 1.670170079024566e-05), (12.0, 6.14421235332821e-06), (13.0, 2.2603294069810542e-06), (14.0, 8.315287191035679e-07), (15.0, 3.059023205018258e-07), (16.0, 1.1253517471925912e-07), (17.0, 4.139937718785167e-08), (18.0, 1.522997974471263e-08), (19.0, 5.602796437537268e-09), (20.0, 2.061153622438558e-09), (21.0, 7.582560427911907e-10), (22.0, 2.7894680928689246e-10), (23.0, 1.026187963170189e-10), (24.0, 3.775134544279098e-11), (25.0, 1.3887943864964021e-11), (26.0, 5.109089028063325e-12), (27.0, 1.8795288165390832e-12), (28.0, 6.914400106940203e-13), (29.0, 2.543665647376923e-13), (30.0, 9.357622968840175e-14), (31.0, 3.442477108469977e-14), (32.0, 1.2664165549094176e-14), (33.0, 4.658886145103398e-15), (34.0, 1.713908431542013e-15), (35.0, 6.305116760146989e-16)]\n",
            "Applying apply_tppr_decay_weights (edge-age decay, in days)...\n",
            "\n",
            "Computing TPPR scores on 4251 nodes and 28163 edges...\n",
            "\n",
            "--- Top 6 Nodes by TPPR Score (2025-04-03 18:00) ---\n",
            "- thị trường bán lẻ việt nam (Type: entity, Sector: N/A, Rel: N/A): 0.01164108\n",
            "- doanh nghiệp ô tô điện việt nam (Type: entity, Sector: N/A, Rel: N/A): 0.00667233\n",
            "- thị trường chứng khoán đông nam á (Type: entity, Sector: N/A, Rel: N/A): 0.00625027\n",
            "- người lao động đông nam á (Type: entity, Sector: N/A, Rel: N/A): 0.00546851\n",
            "- doanh nghiệp xây dựng quảng nam (Type: entity, Sector: N/A, Rel: N/A): 0.00407335\n",
            "- ngành công nghiệp bán dẫn mỹ (Type: entity, Sector: N/A, Rel: N/A): 0.00385977\n",
            "\n",
            "Created subgraph (G_TRR) with 162 nodes and 2065 edges.\n",
            "Top 10 nodes by incoming edges (in G_TRR): [('ngành công nghiệp bán dẫn mỹ', 73), ('doanh nghiệp việt nam', 52), ('người lao động việt nam', 51), ('người tiêu dùng việt nam', 50), ('doanh nghiệp bán dẫn mỹ', 49), ('người tiêu dùng mỹ', 48), ('doanh nghiệp bán lẻ việt nam', 46), ('ngành công nghiệp việt nam', 45), ('thị trường chứng khoán việt nam', 40), ('ngân sách nhà nước việt nam', 40)]\n",
            "Running final reasoning...\n",
            "\n",
            "Tuple đầu vào cho suy luận:\n",
            "Số cạnh: 2065\n",
            "\n",
            "Final Prediction:\n",
            "\n",
            "Prediction for 2025-04-04: N/A\n",
            "\n",
            "All predictions saved to prediction_NER.csv\n",
            "\n",
            "Prediction process finished for all dates.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import networkx as nx\n",
        "import pickle\n",
        "import datetime\n",
        "import argparse\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import random\n",
        "\n",
        "\n",
        "try:\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "    from langchain_core.prompts import PromptTemplate\n",
        "    from google.api_core.exceptions import ResourceExhausted\n",
        "except ImportError:\n",
        "    sys.exit(1)\n",
        "\n",
        "# --- HẰNG SỐ DANH MỤC ---\n",
        "MAX_ITER = 5\n",
        "PORTFOLIO_STOCKS = [\"FPT\", \"SSI\", \"VCB\", \"VHM\", \"HPG\", \"GAS\", \"MSN\", \"MWG\", \"GVR\", \"VCG\"]\n",
        "PORTFOLIO_SECTOR = [\"Công nghệ\", \"Chứng khoán\", \"Ngân hàng\", \"Bất động sản\", \"Vật liệu cơ bản\", \"Dịch vụ Hạ tầng\", \"Tiêu dùng cơ bản\", \"Bán lẻ\", \"Chế biến\", \"Công nghiệp\"]\n",
        "MAX_RETRIES = 3\n",
        "BASE_DELAY = 30\n",
        "DELAY_BETWEEN_DATES_SECONDS = 60 # 1 phút chờ giữa các ngày\n",
        "\n",
        "# --- Khởi tạo LLM và Chain ---\n",
        "chain_reasoning = None\n",
        "\n",
        "try:\n",
        "    API_KEY = \"MY_API_KEY\"\n",
        "\n",
        "    if not API_KEY or API_KEY == \"API_KEY\":\n",
        "        print(\"Lỗi: API Key không hợp lệ.\")\n",
        "        sys.exit(1)\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = API_KEY\n",
        "\n",
        "    model_more_temperature = ChatGoogleGenerativeAI(model = \"gemini-2.5-flash\", temperature= 0.1)\n",
        "\n",
        "    reasoning_template = PromptTemplate.from_template(\"\"\"\n",
        "Dự đoán liệu danh mục cổ phiếu sau có sập giá vào ngày {prediction_date} hay không:\n",
        "\n",
        "Danh mục cổ phiếu:\n",
        "{portfolio}\n",
        "\n",
        "Cho một đồ thị tri thức được biểu diễn dưới dạng quan hệ thời gian và tác động, được biểu diễn dưới dạng các tuple\n",
        "(thời gian, nguồn, hành động, đích), cần dự đoán liệu danh mục cổ phiếu đã nêu có sập giá vào ngày {prediction_date} hay không.\n",
        "\n",
        "Dưới đây là đồ thị tri thức được biểu diễn dưới dạng các tuple (thời gian, nguồn, hành động, đích):\n",
        "{tuples}\n",
        "\n",
        "Lưu ý rằng \"sập giá\" ở đây biểu thị cho một đợt giảm giá của danh mục cổ phiếu RẤT MẠNH (lên tới 2%). Vì vậy cần có phân tích đa chiều, từ nhiều phía khác nhau.\n",
        "Giải thích theo từng bước cho lựa chọn đó, và nêu rõ rằng dự đoán là cho ngày {prediction_date}.\n",
        "\n",
        "Sử dụng lý luận của riêng bạn trên đồ thị được đưa, và không đề cập đến các sự kiện khác ngoài đồ thị có trong quá khứ.\n",
        "\n",
        "Dự đoán dưới định dạng sau:\n",
        "Explanation: [Lý do]\n",
        "Crash: [Yes/No]\n",
        "\n",
        "Lý do sập giá cho chuỗi sự kiện vào ngày {prediction_date}:\n",
        "\"\"\")\n",
        "    chain_reasoning = reasoning_template | model_more_temperature\n",
        "    time.sleep(3)\n",
        "    print(\"Mô hình LLM đã được khởi tạo thành công.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Lỗi: Vui lòng cài đặt thư viện 'langchain-google-genai' (`pip install langchain-google-genai`)\")\n",
        "    sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"Lỗi khi khởi tạo mô hình LLM: {e}\")\n",
        "    print(\"Đảm bảo bạn đã cấu hình API key cho Gemini nếu cần.\")\n",
        "    sys.exit(1) # Thoát nếu khởi tạo LLM thất bại\n",
        "\n",
        "# --- Hàm invoke_chain_with_retry ---\n",
        "def invoke_chain_with_retry(chain, prompt, max_retries=MAX_RETRIES, base_delay=BASE_DELAY):\n",
        "    retry_count = 0\n",
        "    while True:\n",
        "        try:\n",
        "            response = chain.invoke(prompt)\n",
        "            time.sleep(5)  # Độ trễ cố định\n",
        "            return response\n",
        "        except ResourceExhausted as e:\n",
        "            retry_count += 1\n",
        "            if retry_count > max_retries:\n",
        "                print(f\"Đã đạt số lần thử lại tối đa. Lỗi: {e}\")\n",
        "                return None\n",
        "            # Tìm retry_delay trong chuỗi lỗi\n",
        "            retry_after = base_delay\n",
        "            error_str = str(e)\n",
        "            match = re.search(r'retry_delay\\s*\\{\\s*seconds:\\s*(\\d+)\\s*\\}', error_str)\n",
        "            if match:\n",
        "                retry_after = float(match.group(1))\n",
        "            delay = retry_after + random.uniform(0, 1)  # Thêm jitter\n",
        "            print(f\"Lỗi 429: Thử lại sau {delay} giây... (Lần thử {retry_count}/{max_retries})\")\n",
        "            time.sleep(delay)\n",
        "        except Exception as e:\n",
        "            retry_count += 1\n",
        "            if retry_count > max_retries:\n",
        "                print(f\"Đã đạt số lần thử lại tối đa. Lỗi: {e}\")\n",
        "                return None\n",
        "            delay = base_delay * (2 ** (retry_count - 1))\n",
        "            print(f\"Lỗi: {e}. Thử lại sau {delay} giây... (Lần thử {retry_count}/{max_retries})\")\n",
        "            time.sleep(delay)\n",
        "\n",
        "# --- Hàm update_edge_decay_weights ---\n",
        "def update_edge_decay_weights(G: nx.DiGraph, current_time=None, lambda_decay=1) -> nx.DiGraph:\n",
        "    \"\"\"\n",
        "    Updates each edge's weight based on exponential decay from its timestamp.\n",
        "    Assumes node timestamps are available and valid.\n",
        "    Handles timezone consistency by converting all timestamps to UTC aware.\n",
        "    \"\"\"\n",
        "    if current_time is None:\n",
        "        current_time_pd = pd.Timestamp.now(tz='UTC')\n",
        "    else:\n",
        "        try:\n",
        "            current_time_pd = pd.to_datetime(current_time).tz_convert('UTC') if pd.to_datetime(current_time).tz is not None else pd.to_datetime(current_time).tz_localize('UTC')\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting current_time '{current_time}' to pandas Timestamp in update_edge_decay_weights: {e}. Using current UTC time.\")\n",
        "            current_time_pd = pd.Timestamp.now(tz='UTC')\n",
        "\n",
        "    decay_weights_summary = {}\n",
        "    for u, v, data in G.edges(data=True):\n",
        "        u_timestamp_raw = G.nodes[u].get(\"timestamp\")\n",
        "        v_timestamp_raw = G.nodes[v].get(\"timestamp\")\n",
        "\n",
        "        if u_timestamp_raw is None or v_timestamp_raw is None:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            u_ts_val = pd.to_datetime(u_timestamp_raw).tz_convert('UTC') if pd.to_datetime(u_timestamp_raw).tz is not None else pd.to_datetime(u_timestamp_raw).tz_localize('UTC')\n",
        "            v_ts_val = pd.to_datetime(v_timestamp_raw).tz_convert('UTC') if pd.to_datetime(v_timestamp_raw).tz is not None else pd.to_datetime(v_timestamp_raw).tz_localize('UTC')\n",
        "\n",
        "            delta_days = (v_ts_val - u_ts_val).total_seconds() / 86400\n",
        "\n",
        "            if delta_days < 0:\n",
        "                R_decay = 0.0\n",
        "            else:\n",
        "                decay_factor = (1.0 / lambda_decay) if lambda_decay != 0 else 1.0\n",
        "                R_decay = math.exp(-delta_days * decay_factor)\n",
        "\n",
        "            data[\"weight\"] = R_decay\n",
        "\n",
        "            if delta_days >= 0:\n",
        "                decay_weights_summary[round(delta_days, 0)] = R_decay\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not process timestamps for edge ({u}, {v}) with u_ts: '{u_timestamp_raw}' ({type(u_timestamp_raw)}), v_ts: '{v_timestamp_raw}' ({type(v_timestamp_raw)}) in update_edge_decay_weights: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Update Edge Decay Weights Summary (delta_days: decay_value): {sorted(decay_weights_summary.items())}\")\n",
        "    return G\n",
        "\n",
        "# --- Hàm apply_tppr_decay_weights ---\n",
        "def apply_tppr_decay_weights(G: nx.DiGraph, current_time, lambda_decay: float) -> nx.DiGraph:\n",
        "    \"\"\"\n",
        "    Applies time decay to edge weights based on the TPPR formula,\n",
        "    with time differences calculated in DAYS.\n",
        "    Handles timezone consistency by converting all timestamps to UTC aware.\n",
        "    \"\"\"\n",
        "    if not isinstance(current_time, pd.Timestamp):\n",
        "        try:\n",
        "            current_time_pd = pd.to_datetime(current_time).tz_convert('UTC') if pd.to_datetime(current_time).tz is not None else pd.to_datetime(current_time).tz_localize('UTC')\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting current_time '{current_time}' to pandas Timestamp in apply_tppr_decay_weights: {e}. Skipping decay application.\")\n",
        "            return G\n",
        "    else:\n",
        "        current_time_pd = current_time\n",
        "        if current_time_pd.tz is None:\n",
        "            current_time_pd = current_time_pd.tz_localize('UTC')\n",
        "        else:\n",
        "            current_time_pd = current_time_pd.tz_convert('UTC')\n",
        "\n",
        "\n",
        "    for u, v, data in G.edges(data=True):\n",
        "        edge_ts_raw = data.get(\"timestamp\")\n",
        "        if edge_ts_raw is None:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            edge_ts_pd = pd.to_datetime(edge_ts_raw).tz_convert('UTC') if pd.to_datetime(edge_ts_raw).tz is not None else pd.to_datetime(edge_ts_raw).tz_localize('UTC')\n",
        "\n",
        "            time_diff_days = (current_time_pd - edge_ts_pd).total_seconds() / 86400\n",
        "\n",
        "            if time_diff_days < 0:\n",
        "                decay_factor = 0.0\n",
        "            else:\n",
        "                decay_factor = math.exp(-lambda_decay * time_diff_days)\n",
        "\n",
        "            G[u][v]['weight'] = G[u][v].get('weight', 1.0) * decay_factor\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not apply TPPR decay for edge ({u}, {v}) with timestamp '{edge_ts_raw}' ({type(edge_ts_raw)}): {e}\")\n",
        "            continue\n",
        "    return G\n",
        "\n",
        "# --- Hàm attention_phase ---\n",
        "def attention_phase(G, current_time, lambda_decay, q=6):\n",
        "    \"\"\"\n",
        "    Uses Temporal Personalized PageRank (TPPR) to find important entities and their connections.\n",
        "    Creates a filtered copy that only uses edges dated before or on the prediction date.\n",
        "    Splits the graph into connected components and processes the largest component.\n",
        "    Applies time-decayed weights and personalizes ranking based on portfolio stocks and sectors,\n",
        "    with an emphasis on directly influencing nodes.\n",
        "    \"\"\"\n",
        "    G_filtered = G.copy()\n",
        "\n",
        "    if not isinstance(current_time, pd.Timestamp):\n",
        "        try:\n",
        "            current_time_pd = pd.to_datetime(current_time).tz_convert('UTC') if pd.to_datetime(current_time).tz is not None else pd.to_datetime(current_time).tz_localize('UTC')\n",
        "        except ValueError:\n",
        "            print(f\"Error: current_time '{current_time}' cannot be converted to a pandas Timestamp. Using current UTC time (tz-aware).\")\n",
        "            current_time_pd = pd.Timestamp.now(tz='UTC')\n",
        "    else:\n",
        "        current_time_pd = current_time\n",
        "        if current_time_pd.tz is None:\n",
        "            current_time_pd = current_time_pd.tz_localize('UTC')\n",
        "        else:\n",
        "            current_time_pd = current_time_pd.tz_convert('UTC')\n",
        "\n",
        "    print(f\"Using prediction date (UTC aware): {current_time_pd}\")\n",
        "\n",
        "    edges_to_remove = []\n",
        "    for u, v, data in G_filtered.edges(data=True):\n",
        "        edge_time_raw = data.get(\"timestamp\")\n",
        "\n",
        "        if edge_time_raw is None:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            edge_timestamp_pd = pd.to_datetime(edge_time_raw).tz_convert('UTC') if pd.to_datetime(edge_time_raw).tz is not None else pd.to_datetime(edge_time_raw).tz_localize('UTC')\n",
        "\n",
        "            if edge_timestamp_pd > current_time_pd:\n",
        "                edges_to_remove.append((u, v))\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not process timestamp '{edge_time_raw}' for edge ({u}, {v}) during filtering: {e}\")\n",
        "            continue\n",
        "\n",
        "    for u, v in edges_to_remove:\n",
        "        if G_filtered.has_edge(u, v):\n",
        "            G_filtered.remove_edge(u, v)\n",
        "\n",
        "    print(f\"Filtered out {len(edges_to_remove)} future edges from graph for TPPR calculation.\")\n",
        "    print(f\"Graph after future edge filtering: {G_filtered.number_of_nodes()} nodes, {G_filtered.number_of_edges()} edges.\")\n",
        "\n",
        "    # Find the largest weakly connected component\n",
        "    if G_filtered.number_of_nodes() == 0:\n",
        "        print(\"Warning: Graph has no nodes after filtering. Cannot compute PageRank.\")\n",
        "        return nx.DiGraph()\n",
        "\n",
        "    # Convert to undirected for connected components, then back to directed for PageRank\n",
        "    undirected_G = G_filtered.to_undirected()\n",
        "    if not undirected_G.nodes():\n",
        "        print(\"Warning: Undirected graph has no nodes. Cannot compute PageRank.\")\n",
        "        return nx.DiGraph()\n",
        "\n",
        "    components = list(nx.connected_components(undirected_G))\n",
        "    if not components:\n",
        "        print(\"Warning: No connected components found. Cannot compute PageRank.\")\n",
        "        return nx.DiGraph()\n",
        "\n",
        "    largest_component_nodes = max(components, key=len)\n",
        "    G_largest_component = G_filtered.subgraph(largest_component_nodes).copy()\n",
        "\n",
        "    print(f\"Working with largest connected component: {G_largest_component.number_of_nodes()} nodes, {G_largest_component.number_of_edges()} edges.\")\n",
        "\n",
        "    print(\"Applying update_edge_decay_weights (node-to-node temporal decay)...\")\n",
        "    G_temporal = update_edge_decay_weights(G_largest_component, current_time=current_time_pd, lambda_decay=lambda_decay)\n",
        "\n",
        "    print(\"Applying apply_tppr_decay_weights (edge-age decay, in days)...\")\n",
        "    G_temporal = apply_tppr_decay_weights(G_temporal, current_time=current_time_pd, lambda_decay=lambda_decay)\n",
        "\n",
        "    personalization = {}\n",
        "\n",
        "    WEIGHT_DIRECT_INFLUENCER = 5\n",
        "    WEIGHT_PORTFOLIO_ITEM    = 0.5\n",
        "    WEIGHT_OTHER_NODES       = 0.1\n",
        "\n",
        "    portfolio_sector_actual_nodes = set()\n",
        "    for sector_name in PORTFOLIO_SECTOR:\n",
        "        if sector_name in G_temporal:\n",
        "            portfolio_sector_actual_nodes.add(sector_name)\n",
        "\n",
        "    all_portfolio_target_nodes = set(PORTFOLIO_STOCKS) | portfolio_sector_actual_nodes\n",
        "\n",
        "    direct_influencing_nodes = set()\n",
        "    for target_node in all_portfolio_target_nodes:\n",
        "        if target_node in G_temporal:\n",
        "            for neighbor in G_temporal.predecessors(target_node):\n",
        "                direct_influencing_nodes.add(neighbor)\n",
        "            for neighbor in G_temporal.successors(target_node):\n",
        "                direct_influencing_nodes.add(neighbor)\n",
        "\n",
        "    direct_influencing_nodes = direct_influencing_nodes - all_portfolio_target_nodes\n",
        "\n",
        "    num_nodes = G_temporal.number_of_nodes()\n",
        "    if num_nodes == 0:\n",
        "        print(\"Warning: Graph has no nodes. Cannot compute PageRank.\")\n",
        "        return nx.DiGraph()\n",
        "\n",
        "    for node in G_temporal.nodes():\n",
        "        if node in all_portfolio_target_nodes:\n",
        "            personalization[node] = WEIGHT_PORTFOLIO_ITEM\n",
        "        elif node in direct_influencing_nodes:\n",
        "            personalization[node] = WEIGHT_DIRECT_INFLUENCER\n",
        "        else:\n",
        "            personalization[node] = WEIGHT_OTHER_NODES\n",
        "\n",
        "    # Normalize\n",
        "    total_personalization_sum = sum(personalization.values())\n",
        "    if total_personalization_sum > 0:\n",
        "        personalization = {node: value / total_personalization_sum for node, value in personalization.items()}\n",
        "    else:\n",
        "        personalization = {node: 1.0 / num_nodes for node in G_temporal.nodes()}\n",
        "\n",
        "\n",
        "    print(f\"\\nComputing TPPR scores on {G_temporal.number_of_nodes()} nodes and {G_temporal.number_of_edges()} edges...\")\n",
        "\n",
        "    if G_temporal.number_of_nodes() == 0 or G_temporal.number_of_edges() == 0:\n",
        "        print(\"Warning: G_temporal is empty or has no edges. Cannot compute PageRank. Returning empty subgraph.\")\n",
        "        return nx.DiGraph()\n",
        "\n",
        "    pr_scores = nx.pagerank(G_temporal, alpha=0.85, personalization=personalization, weight=\"weight\")\n",
        "\n",
        "    relevant_node_types = [\"entity\", \"stock\", \"stock_industry\", \"sector\", \"person\", \"organization\", \"market_index\", \"economic_factor\", \"financial_instrument\", \"industry\"]\n",
        "    filtered_scores = {node: score for node, score in pr_scores.items()\n",
        "                       if G_temporal.nodes[node].get(\"type\") in relevant_node_types or node in all_portfolio_target_nodes}\n",
        "\n",
        "    if not filtered_scores:\n",
        "        print(\"Warning: No relevant nodes found after filtering for scores. Returning empty subgraph.\")\n",
        "        return nx.DiGraph()\n",
        "\n",
        "    top_nodes = sorted(filtered_scores, key=filtered_scores.get, reverse=True)[:q]\n",
        "\n",
        "    print(f\"\\n--- Top {q} Nodes by TPPR Score ({current_time_pd.strftime('%Y-%m-%d %H:%M')}) ---\")\n",
        "    if not top_nodes:\n",
        "        print(\"No top nodes found based on scores.\")\n",
        "    for node in top_nodes:\n",
        "        score = filtered_scores[node]\n",
        "        node_data = G_temporal.nodes[node]\n",
        "        print(f\"- {node} (Type: {node_data.get('type', 'N/A')}, Sector: {node_data.get('sector', 'N/A')}, Rel: {node_data.get('relation', 'N/A')}): {score:.8f}\")\n",
        "\n",
        "    selected_nodes = set(top_nodes)\n",
        "    for node in top_nodes:\n",
        "        if node in G_temporal:\n",
        "            selected_nodes.update(G_temporal.predecessors(node))\n",
        "            selected_nodes.update(G_temporal.successors(node))\n",
        "            selected_nodes.add(node)\n",
        "\n",
        "    sub_G = G_temporal.subgraph(selected_nodes).copy()\n",
        "\n",
        "    print(f\"\\nCreated subgraph (G_TRR) with {sub_G.number_of_nodes()} nodes and {sub_G.number_of_edges()} edges.\")\n",
        "    print(f\"Top 10 nodes by incoming edges (in G_TRR): {sorted(sub_G.in_degree(), key=lambda x: x[1], reverse=True)[:10]}\")\n",
        "\n",
        "    return sub_G\n",
        "\n",
        "def graph_to_tuples(G):\n",
        "    \"\"\"\n",
        "    Chuyển đổi đồ thị thành một chuỗi các tuple (ngày, nguồn, tác động, đích).\n",
        "    \"\"\"\n",
        "    tuples = []\n",
        "    for u, v, data in G.edges(data=True):\n",
        "        timestamp = data.get(\"timestamp\")\n",
        "        if timestamp is None:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            ts_pd = pd.to_datetime(timestamp).tz_convert('UTC') if pd.to_datetime(timestamp).tz is not None else pd.to_datetime(timestamp).tz_localize('UTC')\n",
        "            date_str = ts_pd.date().isoformat()\n",
        "\n",
        "            if \"không có thực thể nào\" in str(u).lower() or \"không có thực thể nào\" in str(v).lower():\n",
        "                continue\n",
        "\n",
        "            tuples.append(f\"({date_str}, {u}, {data.get('impact')} TO, {v})\")\n",
        "        except Exception as e:\n",
        "            print(f\"Lỗi khi xử lý cạnh ({u}, {v}): {e}, dấu thời gian: {timestamp}, loại: {type(timestamp)}\")\n",
        "            continue\n",
        "\n",
        "    return \"\\n\".join(sorted(tuples))\n",
        "\n",
        "def final_reasoning(G, portfolio, portfolio_sector, prediction_date):\n",
        "    \"\"\"\n",
        "    Chạy chuỗi suy luận cuối cùng với LLM.\n",
        "    \"\"\"\n",
        "    tuples_str = graph_to_tuples(G)\n",
        "\n",
        "    portfolio_str_full = \", \".join(portfolio)\n",
        "\n",
        "    print(\"\\nTuple đầu vào cho suy luận:\")\n",
        "    print(f\"Số cạnh: {G.number_of_edges()}\")\n",
        "\n",
        "    reasoning_prompt = {\n",
        "        \"tuples\": tuples_str,\n",
        "        \"portfolio\": portfolio_str_full,\n",
        "        \"prediction_date\": prediction_date\n",
        "    }\n",
        "\n",
        "    response = invoke_chain_with_retry(chain_reasoning, reasoning_prompt)\n",
        "    time.sleep(2)\n",
        "    return response\n",
        "\n",
        "def trr(prediction_date: str, load_saved_graph: bool = False, lambda_decay: float = 1,\n",
        "        q: int = 6, max_frontier_size: int = 10, use_threading: bool = True, max_workers: int = 5,\n",
        "        skip: int = 0, graph_checkpoint: str = None, canonical_checkpoint: str = None):\n",
        "    \"\"\"\n",
        "    Main TRR function to make predictions using an existing knowledge graph.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        pred_ts = pd.to_datetime(prediction_date).tz_convert('UTC') if pd.to_datetime(prediction_date).tz is not None else pd.to_datetime(prediction_date).tz_localize('UTC')\n",
        "        print(f\"Prediction timestamp (UTC aware): {pred_ts}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing prediction date: {e}. Using prediction_date as is.\")\n",
        "        pred_ts = prediction_date\n",
        "\n",
        "    G = None\n",
        "\n",
        "    if load_saved_graph:\n",
        "        print(\"Attempting to load existing knowledge graph...\")\n",
        "        if not graph_checkpoint:\n",
        "            print(\"Error: 'graph_checkpoint' path is required when 'load_saved_graph' is True.\")\n",
        "            return None\n",
        "        try:\n",
        "            with open(graph_checkpoint, \"rb\") as f:\n",
        "                G = pickle.load(f)\n",
        "            print(f\"Successfully loaded graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges from {graph_checkpoint}\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Knowledge graph file not found at '{graph_checkpoint}'.\")\n",
        "            print(\"Cannot proceed with reasoning without a loaded graph.\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading knowledge graph from '{graph_checkpoint}': {e}\")\n",
        "            print(\"Cannot proceed with reasoning due to graph loading error.\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Error: 'load_saved_graph' must be True to proceed with reasoning using an existing graph.\")\n",
        "        print(\"This function is configured to *only* load existing graphs, not build new ones.\")\n",
        "        return None\n",
        "\n",
        "    if G is None:\n",
        "        print(\"Failed to load knowledge graph. Exiting TRR function.\")\n",
        "        return None\n",
        "\n",
        "    print(\"Applying attention phase (PageRank-based filtering)...\")\n",
        "    print(f\"Using raw prediction date string: {prediction_date}\")\n",
        "\n",
        "    try:\n",
        "        G_sub = attention_phase(G, current_time=pred_ts, lambda_decay=lambda_decay, q=q)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during attention phase: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(\"Running final reasoning...\")\n",
        "    try:\n",
        "        prediction = final_reasoning(G_sub, PORTFOLIO_STOCKS, PORTFOLIO_SECTOR, prediction_date)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during final reasoning: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(\"\\nFinal Prediction:\")\n",
        "    print(prediction.content if prediction else \"No prediction available\")\n",
        "\n",
        "    return prediction\n",
        "\n",
        "def run_date_range_predictions(start_date_str: str, end_date_str: str, graph_path: str, canonical_path: str, **kwargs):\n",
        "    \"\"\"\n",
        "    Runs TRR predictions for a range of dates and saves results to a single CSV.\n",
        "    Appends to the CSV if it already exists.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        start_date = pd.to_datetime(start_date_str).date()\n",
        "        end_date = pd.to_datetime(end_date_str).date()\n",
        "    except ValueError as e:\n",
        "        print(f\"Error parsing start or end date: {e}. Please use ISO 8601 format (e.g., 'YYYY-MM-DD').\")\n",
        "        return\n",
        "\n",
        "    if start_date > end_date:\n",
        "        print(\"Error: Start date cannot be after end date.\")\n",
        "        return\n",
        "\n",
        "    all_predictions_data = []\n",
        "    output_filename = \"prediction_NER.csv\"\n",
        "\n",
        "    if os.path.exists(output_filename):\n",
        "        try:\n",
        "            existing_df = pd.read_csv(output_filename, encoding='utf-8')\n",
        "            all_predictions_data = existing_df.to_dict('records')\n",
        "            print(f\"Loaded {len(all_predictions_data)} existing predictions from {output_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load existing {output_filename} due to error: {e}. Starting with an empty prediction set.\")\n",
        "            all_predictions_data = []\n",
        "\n",
        "    current_date = start_date\n",
        "    while current_date <= end_date:\n",
        "        prediction_date_str = f\"{current_date.isoformat()}T01:00:00+07:00\"\n",
        "        print(f\"\\n--- Starting prediction for date: {prediction_date_str} ---\")\n",
        "\n",
        "        # Call the TRR function for the current date\n",
        "        prediction_result = trr(\n",
        "            prediction_date_str,\n",
        "            load_saved_graph=True,\n",
        "            graph_checkpoint=graph_path,\n",
        "            canonical_checkpoint=canonical_path,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        if prediction_result and hasattr(prediction_result, 'content'):\n",
        "            full_response = prediction_result.content\n",
        "            # Extract 'Crash: [Yes/No]' from the full response\n",
        "            match = re.search(r\"Crash:\\s*(Yes|No)\", full_response, re.IGNORECASE)\n",
        "            predict_value = match.group(1) if match else \"N/A\"\n",
        "            print(f\"Prediction for {current_date.isoformat()}: {predict_value}\")\n",
        "\n",
        "            all_predictions_data.append({\n",
        "                \"time\": current_date.isoformat(),\n",
        "                \"predict\": predict_value,\n",
        "                \"full_response\": full_response\n",
        "            })\n",
        "        else:\n",
        "            print(f\"No valid prediction content for {current_date.isoformat()}\")\n",
        "            all_predictions_data.append({\n",
        "                \"time\": current_date.isoformat(),\n",
        "                \"predict\": \"Error/No_Response\",\n",
        "                \"full_response\": \"No prediction content received or an error occurred.\"\n",
        "            })\n",
        "\n",
        "        current_date += datetime.timedelta(days=1)\n",
        "\n",
        "        if current_date <= end_date: # Only delay if there are more dates to process\n",
        "            print(f\"Waiting {DELAY_BETWEEN_DATES_SECONDS} seconds before next prediction...\")\n",
        "            time.sleep(DELAY_BETWEEN_DATES_SECONDS)\n",
        "\n",
        "    # Save all collected predictions to a single CSV file (including appended data)\n",
        "    output_df = pd.DataFrame(all_predictions_data)\n",
        "    try:\n",
        "        output_df.to_csv(output_filename, index=False, encoding='utf-8')\n",
        "        print(f\"\\nAll predictions saved to {output_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving all predictions to {output_filename}: {e}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main entry point for Temporal Relational Reasoning Model - Prediction Mode\n",
        "    Handles command-line arguments for date range prediction.\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Temporal Relational Reasoning Model - Prediction Mode\")\n",
        "    parser.add_argument(\"--start_date\", type=str, default=\"2025-04-01\", help=\"Start date for predictions (YYYY-MM-DD)\")\n",
        "    parser.add_argument(\"--end_date\", type=str, default=\"2025-04-03\", help=\"End date for predictions (YYYY-MM-DD)\")\n",
        "    parser.add_argument(\"--lambda_decay\", type=float, default=1.0, help=\"Lambda decay parameter\")\n",
        "    parser.add_argument(\"--q\", type=int, default=6, help=\"Top-q entities to select in subgraph\")\n",
        "    parser.add_argument(\"--max_frontier_size\", type=int, default=10, help=\"Maximum number of entities to process in a single batch (for TRR internal use)\")\n",
        "    parser.add_argument(\"--no_threading\", action=\"store_true\", help=\"Disable multithreading for TRR processing\")\n",
        "    parser.add_argument(\"--max_workers\", type=int, default=5, help=\"Maximum number of worker threads for TRR processing\")\n",
        "    parser.add_argument(\"--skip\", type=int, default=0, help=\"Number of articles to skip in TRR processing (if applicable)\")\n",
        "    parser.add_argument(\"--graph_checkpoint\", type=str, default=\"graph.pkl\", help=\"Path to knowledge graph checkpoint file to load (e.g., graph.pkl)\")\n",
        "    parser.add_argument(\"--canonical_checkpoint\", type=str, default=\"canonical_set.pkl\", help=\"Path to canonical entities checkpoint file to load (e.g., canonical_set.pkl)\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(\"Proceeding with reasoning using pre-loaded knowledge graph data...\")\n",
        "    print(f\"Running TRR for date range: {args.start_date} to {args.end_date}\")\n",
        "\n",
        "    run_date_range_predictions(\n",
        "        start_date_str=args.start_date,\n",
        "        end_date_str=args.end_date,\n",
        "        graph_path=args.graph_checkpoint,\n",
        "        canonical_path=args.canonical_checkpoint,\n",
        "        lambda_decay=args.lambda_decay,\n",
        "        q=args.q,\n",
        "        max_frontier_size=args.max_frontier_size,\n",
        "        use_threading=not args.no_threading,\n",
        "        max_workers=args.max_workers,\n",
        "        skip=args.skip\n",
        "    )\n",
        "\n",
        "    print(\"\\nPrediction process finished for all dates.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    graph_path = '/content/knowledge_graph_p3_fixed_0227-0407.pkl'\n",
        "    canonical_path = '/content/canonical_set_0227-0407.pkl'\n",
        "\n",
        "    # Check if files exist before attempting to run\n",
        "    if not os.path.exists(graph_path):\n",
        "        print(f\"Error: Graph checkpoint file not found at {graph_path}. Please ensure it's uploaded.\")\n",
        "        sys.exit(1)\n",
        "    if not os.path.exists(canonical_path):\n",
        "        print(f\"Error: Canonical checkpoint file not found at {canonical_path}. Please ensure it's uploaded.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Simulate command-line arguments\n",
        "    sys.argv = [\n",
        "        'your_script_name.py',\n",
        "        '--start_date', '2025-03-31', # Start date for prediction\n",
        "        '--end_date', '2025-04-04',   # End date for prediction\n",
        "        '--graph_checkpoint', graph_path,\n",
        "        '--canonical_checkpoint', canonical_path,\n",
        "        '--lambda_decay', '1.0',\n",
        "        '--q', '6',\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        main()\n",
        "    except SystemExit as e:\n",
        "        if e.code != 0:\n",
        "            print(f\"An error occurred during argument parsing or execution: {e}\")\n",
        "        else:\n",
        "            print(\"Argument parsing completed successfully (e.g., --help was called).\")\n"
      ],
      "metadata": {
        "id": "LfoDPF3-LJIa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}